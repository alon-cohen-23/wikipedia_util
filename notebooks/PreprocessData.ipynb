{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce72df9",
   "metadata": {},
   "source": [
    "# Translator Project: preprocess data\n",
    "\n",
    "This Notebook prepares the data for loading and testing the model. Based on code provided by Dekel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d780a",
   "metadata": {},
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a06dd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2023-11-23 18:19:55.340527: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-23 18:20:00.179667: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-23 18:20:06.291653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-11-23 18:20:06.291806: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-11-23 18:20:06.291817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict, load_from_disk\n",
    "import os\n",
    "\n",
    "OUTPUT_DIRECTORY = os.path.join(os.getcwd(), 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca863df5",
   "metadata": {},
   "source": [
    "## Organize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0a9301a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'en': ' Local government leaders and the Unit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': ' The flag was officially adopted on Ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': ' The flag was raised for the first tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'en': ' The previous year, the flag design wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'en': ' A draft was sent to the Institute of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463243</th>\n",
       "      <td>{'en': ' However, this did not last for years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463245</th>\n",
       "      <td>{'en': ' Despite quite a few losses, the Scots...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463247</th>\n",
       "      <td>{'en': ' After the Second World War Scottish i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463249</th>\n",
       "      <td>{'en': ' Scotland is part of the four nations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463250</th>\n",
       "      <td>{'en': 'Therefore, Scotland is subject first a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1312159 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               translation\n",
       "0        {'en': ' Local government leaders and the Unit...\n",
       "1        {'en': ' The flag was officially adopted on Ap...\n",
       "2        {'en': ' The flag was raised for the first tim...\n",
       "3        {'en': ' The previous year, the flag design wo...\n",
       "4        {'en': ' A draft was sent to the Institute of ...\n",
       "...                                                    ...\n",
       "1463243  {'en': ' However, this did not last for years,...\n",
       "1463245  {'en': ' Despite quite a few losses, the Scots...\n",
       "1463247  {'en': ' After the Second World War Scottish i...\n",
       "1463249  {'en': ' Scotland is part of the four nations ...\n",
       "1463250  {'en': 'Therefore, Scotland is subject first a...\n",
       "\n",
       "[1312159 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length = 200\n",
    "max_target_length = 200\n",
    "dataset_name = \"wiki\"\n",
    "\n",
    "df_path = f\"/home/azureuser/translator/tr_data/{dataset_name}/translated_{dataset_name}_final.parquet\"\n",
    "df = pd.read_parquet(df_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2bf97",
   "metadata": {},
   "source": [
    "# Split to training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1b93223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265691</th>\n",
       "      <td>{'en': ' During the Gulf War, US Air Force pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385531</th>\n",
       "      <td>{'en': ' The association observes that a menta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80583</th>\n",
       "      <td>{'en': ' In 1977 he developed a DNA labeling m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906164</th>\n",
       "      <td>{'en': ' What information do they give?', 'he'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352722</th>\n",
       "      <td>{'en': ' \"Allah is our Lord and your Lord, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123023</th>\n",
       "      <td>{'en': ' 1939 - Billie Holiday records the son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288712</th>\n",
       "      <td>{'en': ' B, an opinion is presented that the J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147045</th>\n",
       "      <td>{'en': ' In 2003, the new Rolls-Royce from BMW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746666</th>\n",
       "      <td>{'en': ' Given an electric circuit with two vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135846</th>\n",
       "      <td>{'en': ' In the shadow of the crescent: the hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984119 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              translation\n",
       "265691  {'en': ' During the Gulf War, US Air Force pla...\n",
       "385531  {'en': ' The association observes that a menta...\n",
       "80583   {'en': ' In 1977 he developed a DNA labeling m...\n",
       "906164  {'en': ' What information do they give?', 'he'...\n",
       "352722  {'en': ' \"Allah is our Lord and your Lord, but...\n",
       "...                                                   ...\n",
       "123023  {'en': ' 1939 - Billie Holiday records the son...\n",
       "288712  {'en': ' B, an opinion is presented that the J...\n",
       "147045  {'en': ' In 2003, the new Rolls-Royce from BMW...\n",
       "746666  {'en': ' Given an electric circuit with two vo...\n",
       "135846  {'en': ' In the shadow of the crescent: the hi...\n",
       "\n",
       "[984119 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.25\n",
    "random_state = 42\n",
    "\n",
    "# Split the dataset into a train set and a validation set (small amount)  \n",
    "train_df, val_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "\n",
    "#if want to control the size of the training data, can do it here:\n",
    "#if train_size > 0:\n",
    "#    train_df = train_df.iloc[:train_size]  \n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b86fc4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1afa33a6fc04f91bc7e30d3776bdd6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/984119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70434e9b554c42989c3366b2b80f882c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/328040 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = f\"{dataset_name}_he_en\"\n",
    "train_dataset = Dataset.from_pandas(train_df)  \n",
    "train_dataset = train_dataset.remove_columns(['__index_level_0__'])  # Remove '__index_level_0__' feature from the datasets  \n",
    "val_dataset = Dataset.from_pandas(val_df)    \n",
    "val_dataset = val_dataset.remove_columns(['__index_level_0__'])  \n",
    "\n",
    "split_datasets = DatasetDict({  \n",
    "    'train' : train_dataset,  \n",
    "    'validation' : val_dataset,  \n",
    "    })  \n",
    "\n",
    "data_folder = Path(df_path).parent  \n",
    "train_df.to_parquet(data_folder / 'train.parquet')  \n",
    "val_df.to_parquet(data_folder / 'validation.parquet')  \n",
    "split_datasets.save_to_disk(data_folder / dataset_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c5ff6",
   "metadata": {},
   "source": [
    "## Tokenize (prepare input for model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39e8eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = \"heb_Hebr\"\n",
    "tgt_lang=\"eng_Latn\"\n",
    "model_checkpoint = \"facebook/nllb-200-distilled-1.3B\" \n",
    "tokenizer = NllbTokenizer.from_pretrained(model_checkpoint, src_lang=src_lang, tgt_lang=tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ce0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd552e3192604494b8b8b027fceaaaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/984119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"he\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# if stored once, instead of running split_datasets, run:\n",
    "# tokenized_datasets.load_from_disk(\"/home/azureuser/translator/wiki_data/wiki_dataset\")\n",
    "\n",
    "tokenized_datasets = split_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split_datasets[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1d88813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325b8259c8a949778a10abc933299ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8231 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67800fc1dd3422d8d0de6745e0fcb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2744 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_folder = Path(df_path).parent\n",
    "tokenized_datasets.save_to_disk(f\"{data_folder}/prepared_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce2ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
