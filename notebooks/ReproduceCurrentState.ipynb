{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce72df9",
   "metadata": {},
   "source": [
    "# Translator Project\n",
    "\n",
    "This Notebook provide an easy way to load and test the Model. This follows the code provided by Dekel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d780a",
   "metadata": {},
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a06dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict, load_from_disk, concatenate_datasets\n",
    "import os\n",
    "\n",
    "OUTPUT_DIRECTORY = os.path.join(os.getcwd(), 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca863df5",
   "metadata": {},
   "source": [
    "## Organize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0a9301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocessing needs to be done in an other Notebook\n",
    "# We should easily load from here the split_datasets\n",
    "\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "\n",
    "tokenized_datasets_teheran = load_from_disk('/home/azureuser/translator/tr_data/teheran/prepared_dataset')\n",
    "tokenized_datasets_fauda = load_from_disk('/home/azureuser/translator/tr_data/fauda/prepared_dataset')\n",
    "tokenized_datasets_inss = load_from_disk('/home/azureuser/translator/tr_data/inss/prepared_dataset')\n",
    "tokenized_datasets_wiki = load_from_disk('/home/azureuser/translator/tr_data/wiki/prepared_dataset')\n",
    "\n",
    "train_dataset = concatenate_datasets([\n",
    "    tokenized_datasets_teheran['train'],\n",
    "    tokenized_datasets_fauda['train'],\n",
    "    tokenized_datasets_inss['train'],\n",
    "    tokenized_datasets_wiki['train']\n",
    "])\n",
    "\n",
    "validation_dataset = concatenate_datasets([\n",
    "    tokenized_datasets_teheran['validation'],\n",
    "    tokenized_datasets_fauda['validation'],\n",
    "    tokenized_datasets_inss['validation'],\n",
    "    tokenized_datasets_wiki['validation']\n",
    "])\n",
    "\n",
    "\n",
    "tokenized_datasets = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'validation': validation_dataset,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3ffae89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0317721bc574993b1e813541d59b029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/24693 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aaa4d3a00924c0dabd715624c70c130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8232 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets.save_to_disk('./tr_data/tokenized_dataset_used')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59c026",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e6465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = \"heb_Hebr\"\n",
    "tgt_lang = \"eng_Latn\"\n",
    "\n",
    "model_checkpoint = \"facebook/nllb-200-distilled-1.3B\" \n",
    "# Using local version\n",
    "# model_checkpoint = \"/data2/translation/nllb/nllb-200-distilled-600M-he-en/checkpoint-124998/\" \n",
    "\n",
    "\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_checkpoint, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d88bc7",
   "metadata": {},
   "source": [
    "## Load The metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f151581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"sacrebleu\")\n",
    "\n",
    "f1_scores = []\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # In case the model returns more than the prediction logits\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100s in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    # calculate the f1 score\n",
    "    f1 = f1_score(decoded_labels, decoded_preds, average='weighted')\n",
    "\n",
    "    # calculate scalerblue results\n",
    "    scalerbleu_result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    # bleu_result = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # connects the metrics to wandb\n",
    "\n",
    "    # Log F1 score to WandB\n",
    "    res = {\"sacrebleu\": scalerbleu_result[\"score\"], \"f1_score\": f1}\n",
    "\n",
    "    # Append the F1 score to the list for tracking\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcd534",
   "metadata": {},
   "source": [
    "## Setup Train Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee94846",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    OUTPUT_DIRECTORY,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_accumulation_steps=3,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset= tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2882e82b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1544' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1544/1544 20:52, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Sacrebleu</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.242549</td>\n",
       "      <td>75.563790</td>\n",
       "      <td>0.429968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.262334</td>\n",
       "      <td>75.537487</td>\n",
       "      <td>0.433248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1544, training_loss=0.16169172000390877, metrics={'train_runtime': 1252.8723, 'train_samples_per_second': 39.418, 'train_steps_per_second': 1.232, 'total_flos': 1.0506107625037824e+16, 'train_loss': 0.16169172000390877, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee88f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./models/tranlator-1.3-all-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf6883b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
